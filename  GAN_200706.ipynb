{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":" GAN_200706.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPxQi9dvfgF632Wr1AVcSev"},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"8972f2d7dae84fce87cd4e640830e153":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_29c47d6da2f34eeebcda8885e68e6d2f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_730170dd59754c60ba9d46c024b84baf","IPY_MODEL_f095f645f53a4b1da03480e1228d756c"]}},"29c47d6da2f34eeebcda8885e68e6d2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"730170dd59754c60ba9d46c024b84baf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9627387053aa46d0b5465b6f09bf32b3","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9089bf289f2e4795a20bb7024a27306c"}},"f095f645f53a4b1da03480e1228d756c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4d8d12f827444932b97a0cef2756318d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9920512/? [00:20&lt;00:00, 1365074.39it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fd920c23d1a94201a649a8b05957342a"}},"9627387053aa46d0b5465b6f09bf32b3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9089bf289f2e4795a20bb7024a27306c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4d8d12f827444932b97a0cef2756318d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fd920c23d1a94201a649a8b05957342a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5df5709dea5b4b19bc1a5e779cdb5014":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2ec4d06c532749028a767792ac5f6e67","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_596f6265040142b082554ad1ddb8cdbf","IPY_MODEL_f0bb1c2e933a4314a62ca5cb681b5d69"]}},"2ec4d06c532749028a767792ac5f6e67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"596f6265040142b082554ad1ddb8cdbf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_497cc370cc684ba59d6bbdc755a3813b","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c3054bcc39d5409ca7e1f55bb98e8a33"}},"f0bb1c2e933a4314a62ca5cb681b5d69":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9fc9304cfe57479ba1536882d421ca3c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 32768/? [00:16&lt;00:00, 75454.80it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d1c6d616136f495f8dfc9d0e96fe27e5"}},"497cc370cc684ba59d6bbdc755a3813b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c3054bcc39d5409ca7e1f55bb98e8a33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9fc9304cfe57479ba1536882d421ca3c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d1c6d616136f495f8dfc9d0e96fe27e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6c60f60203ef4269a56b068d94dabe57":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3f5f94bc106c49f9a298a6dc04f98038","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_eb156d355e1b4bdc9b27b17af813ae0b","IPY_MODEL_86588e44887247e7a85484d328874358"]}},"3f5f94bc106c49f9a298a6dc04f98038":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eb156d355e1b4bdc9b27b17af813ae0b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0fcb9f897fcf4437b755c07c63fca054","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c14d725176704268b2bb93ec2ed8a0a5"}},"86588e44887247e7a85484d328874358":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e8412bd0e3d04fa09df8b9a660351b1e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1654784/? [00:02&lt;00:00, 671433.43it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_511adef29b594ac185bbeb68861608c0"}},"0fcb9f897fcf4437b755c07c63fca054":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c14d725176704268b2bb93ec2ed8a0a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e8412bd0e3d04fa09df8b9a660351b1e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"511adef29b594ac185bbeb68861608c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a137c318bd5f41528ea0d17de68d72ab":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_51fb40aa35c54864b73f68e31f0aad78","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9f414298cc4441eaac6b42e4ecbed566","IPY_MODEL_6be0a9b7002040d2b37a090fb567683e"]}},"51fb40aa35c54864b73f68e31f0aad78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9f414298cc4441eaac6b42e4ecbed566":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_52fc87acfc604a9a98cc98aaa922ec88","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3ff9e3c2933e4426adbd32f98fc79343"}},"6be0a9b7002040d2b37a090fb567683e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9028f6f3ab8f421889c72a1f984db1ea","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 8192/? [00:00&lt;00:00, 13071.40it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_46d4b5e9450b41f78a81820469a6e8f1"}},"52fc87acfc604a9a98cc98aaa922ec88":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3ff9e3c2933e4426adbd32f98fc79343":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9028f6f3ab8f421889c72a1f984db1ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"46d4b5e9450b41f78a81820469a6e8f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"jbPm3w6iqqw0","colab_type":"text"},"source":["출처 : \n","https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/03-advanced/generative_adversarial_network/main.py#L41-L57"]},{"cell_type":"code","metadata":{"id":"HAixoMIZqhTQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["8972f2d7dae84fce87cd4e640830e153","29c47d6da2f34eeebcda8885e68e6d2f","730170dd59754c60ba9d46c024b84baf","f095f645f53a4b1da03480e1228d756c","9627387053aa46d0b5465b6f09bf32b3","9089bf289f2e4795a20bb7024a27306c","4d8d12f827444932b97a0cef2756318d","fd920c23d1a94201a649a8b05957342a","5df5709dea5b4b19bc1a5e779cdb5014","2ec4d06c532749028a767792ac5f6e67","596f6265040142b082554ad1ddb8cdbf","f0bb1c2e933a4314a62ca5cb681b5d69","497cc370cc684ba59d6bbdc755a3813b","c3054bcc39d5409ca7e1f55bb98e8a33","9fc9304cfe57479ba1536882d421ca3c","d1c6d616136f495f8dfc9d0e96fe27e5","6c60f60203ef4269a56b068d94dabe57","3f5f94bc106c49f9a298a6dc04f98038","eb156d355e1b4bdc9b27b17af813ae0b","86588e44887247e7a85484d328874358","0fcb9f897fcf4437b755c07c63fca054","c14d725176704268b2bb93ec2ed8a0a5","e8412bd0e3d04fa09df8b9a660351b1e","511adef29b594ac185bbeb68861608c0","a137c318bd5f41528ea0d17de68d72ab","51fb40aa35c54864b73f68e31f0aad78","9f414298cc4441eaac6b42e4ecbed566","6be0a9b7002040d2b37a090fb567683e","52fc87acfc604a9a98cc98aaa922ec88","3ff9e3c2933e4426adbd32f98fc79343","9028f6f3ab8f421889c72a1f984db1ea","46d4b5e9450b41f78a81820469a6e8f1"]},"outputId":"8463014b-8713-4e07-a73c-2ee70b25dc79"},"source":["import os\n","import torch\n","import torchvision\n","import torch.nn as nn\n","from torchvision import transforms\n","from torchvision.utils import save_image\n","\n","\n","# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Hyper-parameters\n","latent_size = 64\n","hidden_size = 256\n","image_size = 784\n","num_epochs = 200\n","batch_size = 100\n","sample_dir = 'samples'\n","\n","# Create a directory if not exists\n","if not os.path.exists(sample_dir):\n","    os.makedirs(sample_dir)\n","\n","# Image processing\n","# transform = transforms.Compose([\n","#                 transforms.ToTensor(),\n","#                 transforms.Normalize(mean=(0.5, 0.5, 0.5),   # 3 for RGB channels\n","#                                      std=(0.5, 0.5, 0.5))])\n","transform = transforms.Compose([\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean=[0.5],   # 1 for greyscale channels\n","                                     std=[0.5])])\n","\n","# MNIST dataset\n","mnist = torchvision.datasets.MNIST(root='../../data/',\n","                                   train=True,\n","                                   transform=transform,\n","                                   download=True)\n","\n","# Data loader\n","data_loader = torch.utils.data.DataLoader(dataset=mnist,\n","                                          batch_size=batch_size, \n","                                          shuffle=True)\n","\n","# Discriminator\n","D = nn.Sequential(\n","    nn.Linear(image_size, hidden_size),\n","    nn.LeakyReLU(0.2),\n","    nn.Linear(hidden_size, hidden_size),\n","    nn.LeakyReLU(0.2),\n","    nn.Linear(hidden_size, 1),\n","    nn.Sigmoid())\n","\n","# Generator \n","G = nn.Sequential(\n","    nn.Linear(latent_size, hidden_size),\n","    nn.ReLU(),\n","    nn.Linear(hidden_size, hidden_size),\n","    nn.ReLU(),\n","    nn.Linear(hidden_size, image_size),\n","    nn.Tanh())\n","\n","# Device setting\n","D = D.to(device)\n","G = G.to(device)\n","\n","# Binary cross entropy loss and optimizer\n","criterion = nn.BCELoss()\n","d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0002)\n","g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002)\n","\n","def denorm(x):\n","    out = (x + 1) / 2\n","    return out.clamp(0, 1)\n","\n","def reset_grad():\n","    d_optimizer.zero_grad()\n","    g_optimizer.zero_grad()\n","\n","# Start training\n","total_step = len(data_loader)\n","for epoch in range(num_epochs):\n","    for i, (images, _) in enumerate(data_loader):\n","        images = images.reshape(batch_size, -1).to(device)\n","        \n","        # Create the labels which are later used as input for the BCE loss\n","        real_labels = torch.ones(batch_size, 1).to(device)\n","        fake_labels = torch.zeros(batch_size, 1).to(device)\n","\n","        # ================================================================== #\n","        #                      Train the discriminator                       #\n","        # ================================================================== #\n","\n","        # Compute BCE_Loss using real images where BCE_Loss(x, y): - y * log(D(x)) - (1-y) * log(1 - D(x))\n","        # Second term of the loss is always zero since real_labels == 1\n","        outputs = D(images)\n","        d_loss_real = criterion(outputs, real_labels)\n","        real_score = outputs\n","        \n","        # Compute BCELoss using fake images\n","        # First term of the loss is always zero since fake_labels == 0\n","        z = torch.randn(batch_size, latent_size).to(device)\n","        fake_images = G(z)\n","        outputs = D(fake_images)\n","        d_loss_fake = criterion(outputs, fake_labels)\n","        fake_score = outputs\n","        \n","        # Backprop and optimize\n","        d_loss = d_loss_real + d_loss_fake\n","        reset_grad()\n","        d_loss.backward()\n","        d_optimizer.step()\n","        \n","        # ================================================================== #\n","        #                        Train the generator                         #\n","        # ================================================================== #\n","\n","        # Compute loss with fake images\n","        z = torch.randn(batch_size, latent_size).to(device)\n","        fake_images = G(z)\n","        outputs = D(fake_images)\n","        \n","        # We train G to maximize log(D(G(z)) instead of minimizing log(1-D(G(z)))\n","        # For the reason, see the last paragraph of section 3. https://arxiv.org/pdf/1406.2661.pdf\n","        g_loss = criterion(outputs, real_labels)\n","        \n","        # Backprop and optimize\n","        reset_grad()\n","        g_loss.backward()\n","        g_optimizer.step()\n","        \n","        if (i+1) % 200 == 0:\n","            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n","                  .format(epoch, num_epochs, i+1, total_step, d_loss.item(), g_loss.item(), \n","                          real_score.mean().item(), fake_score.mean().item()))\n","    \n","    # Save real images\n","    if (epoch+1) == 1:\n","        images = images.reshape(images.size(0), 1, 28, 28)\n","        save_image(denorm(images), os.path.join(sample_dir, 'real_images.png'))\n","    \n","    # Save sampled images\n","    fake_images = fake_images.reshape(fake_images.size(0), 1, 28, 28)\n","    save_image(denorm(fake_images), os.path.join(sample_dir, 'fake_images-{}.png'.format(epoch+1)))\n","\n","# Save the model checkpoints \n","torch.save(G.state_dict(), 'G.ckpt')\n","torch.save(D.state_dict(), 'D.ckpt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../../data/MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8972f2d7dae84fce87cd4e640830e153","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ../../data/MNIST/raw/train-images-idx3-ubyte.gz to ../../data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5df5709dea5b4b19bc1a5e779cdb5014","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ../../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../../data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6c60f60203ef4269a56b068d94dabe57","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../../data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a137c318bd5f41528ea0d17de68d72ab","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../../data/MNIST/raw\n","Processing...\n","Done!\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch [0/200], Step [200/600], d_loss: 0.0460, g_loss: 3.9478, D(x): 1.00, D(G(z)): 0.04\n","Epoch [0/200], Step [400/600], d_loss: 0.0615, g_loss: 5.8227, D(x): 0.99, D(G(z)): 0.04\n","Epoch [0/200], Step [600/600], d_loss: 0.0563, g_loss: 4.9978, D(x): 0.98, D(G(z)): 0.04\n","Epoch [1/200], Step [200/600], d_loss: 0.0305, g_loss: 5.2569, D(x): 0.99, D(G(z)): 0.02\n","Epoch [1/200], Step [400/600], d_loss: 0.4084, g_loss: 4.4171, D(x): 0.88, D(G(z)): 0.13\n","Epoch [1/200], Step [600/600], d_loss: 0.1522, g_loss: 5.2465, D(x): 0.95, D(G(z)): 0.05\n","Epoch [2/200], Step [200/600], d_loss: 0.1702, g_loss: 3.3827, D(x): 0.92, D(G(z)): 0.05\n","Epoch [2/200], Step [400/600], d_loss: 0.2569, g_loss: 2.7792, D(x): 0.91, D(G(z)): 0.09\n","Epoch [2/200], Step [600/600], d_loss: 0.3403, g_loss: 4.1231, D(x): 0.90, D(G(z)): 0.14\n","Epoch [3/200], Step [200/600], d_loss: 0.1023, g_loss: 5.1967, D(x): 0.95, D(G(z)): 0.04\n","Epoch [3/200], Step [400/600], d_loss: 0.4527, g_loss: 4.4215, D(x): 0.87, D(G(z)): 0.17\n","Epoch [3/200], Step [600/600], d_loss: 0.3862, g_loss: 2.7883, D(x): 0.86, D(G(z)): 0.13\n","Epoch [4/200], Step [200/600], d_loss: 0.3606, g_loss: 4.1292, D(x): 0.85, D(G(z)): 0.07\n","Epoch [4/200], Step [400/600], d_loss: 0.2210, g_loss: 3.2624, D(x): 0.95, D(G(z)): 0.14\n","Epoch [4/200], Step [600/600], d_loss: 0.3671, g_loss: 4.3666, D(x): 0.85, D(G(z)): 0.03\n","Epoch [5/200], Step [200/600], d_loss: 0.4445, g_loss: 2.9069, D(x): 0.88, D(G(z)): 0.14\n","Epoch [5/200], Step [400/600], d_loss: 0.9886, g_loss: 3.0628, D(x): 0.80, D(G(z)): 0.28\n","Epoch [5/200], Step [600/600], d_loss: 0.3071, g_loss: 4.9958, D(x): 0.87, D(G(z)): 0.02\n","Epoch [6/200], Step [200/600], d_loss: 0.1744, g_loss: 3.9138, D(x): 0.95, D(G(z)): 0.03\n","Epoch [6/200], Step [400/600], d_loss: 0.2143, g_loss: 4.3162, D(x): 0.97, D(G(z)): 0.13\n","Epoch [6/200], Step [600/600], d_loss: 0.3579, g_loss: 3.6183, D(x): 0.87, D(G(z)): 0.05\n","Epoch [7/200], Step [200/600], d_loss: 0.1295, g_loss: 5.3980, D(x): 0.97, D(G(z)): 0.07\n","Epoch [7/200], Step [400/600], d_loss: 0.0941, g_loss: 4.2960, D(x): 0.97, D(G(z)): 0.04\n","Epoch [7/200], Step [600/600], d_loss: 0.3945, g_loss: 2.8269, D(x): 0.93, D(G(z)): 0.16\n","Epoch [8/200], Step [200/600], d_loss: 0.1036, g_loss: 5.7687, D(x): 0.97, D(G(z)): 0.04\n","Epoch [8/200], Step [400/600], d_loss: 0.2402, g_loss: 4.4610, D(x): 0.96, D(G(z)): 0.11\n","Epoch [8/200], Step [600/600], d_loss: 0.0646, g_loss: 5.6607, D(x): 0.97, D(G(z)): 0.02\n","Epoch [9/200], Step [200/600], d_loss: 0.1316, g_loss: 4.6777, D(x): 0.97, D(G(z)): 0.06\n","Epoch [9/200], Step [400/600], d_loss: 0.1883, g_loss: 6.5132, D(x): 0.93, D(G(z)): 0.01\n","Epoch [9/200], Step [600/600], d_loss: 0.2667, g_loss: 5.5185, D(x): 0.93, D(G(z)): 0.01\n","Epoch [10/200], Step [200/600], d_loss: 0.1016, g_loss: 5.7901, D(x): 0.96, D(G(z)): 0.03\n","Epoch [10/200], Step [400/600], d_loss: 0.0806, g_loss: 5.6730, D(x): 0.99, D(G(z)): 0.06\n","Epoch [10/200], Step [600/600], d_loss: 0.1253, g_loss: 5.2957, D(x): 0.96, D(G(z)): 0.04\n","Epoch [11/200], Step [200/600], d_loss: 0.2518, g_loss: 5.0369, D(x): 0.96, D(G(z)): 0.13\n","Epoch [11/200], Step [400/600], d_loss: 0.1289, g_loss: 4.0712, D(x): 0.98, D(G(z)): 0.08\n","Epoch [11/200], Step [600/600], d_loss: 0.0912, g_loss: 4.3216, D(x): 0.97, D(G(z)): 0.04\n","Epoch [12/200], Step [200/600], d_loss: 0.0693, g_loss: 6.0957, D(x): 0.96, D(G(z)): 0.01\n","Epoch [12/200], Step [400/600], d_loss: 0.0202, g_loss: 8.4476, D(x): 0.99, D(G(z)): 0.00\n","Epoch [12/200], Step [600/600], d_loss: 0.0927, g_loss: 4.7557, D(x): 0.99, D(G(z)): 0.05\n","Epoch [13/200], Step [200/600], d_loss: 0.1493, g_loss: 7.8572, D(x): 0.96, D(G(z)): 0.04\n","Epoch [13/200], Step [400/600], d_loss: 0.0934, g_loss: 6.8646, D(x): 0.96, D(G(z)): 0.01\n","Epoch [13/200], Step [600/600], d_loss: 0.0931, g_loss: 6.6033, D(x): 0.98, D(G(z)): 0.04\n","Epoch [14/200], Step [200/600], d_loss: 0.0994, g_loss: 6.6598, D(x): 0.96, D(G(z)): 0.01\n","Epoch [14/200], Step [400/600], d_loss: 0.1065, g_loss: 4.9676, D(x): 0.95, D(G(z)): 0.02\n","Epoch [14/200], Step [600/600], d_loss: 0.1545, g_loss: 7.0036, D(x): 0.96, D(G(z)): 0.01\n","Epoch [15/200], Step [200/600], d_loss: 0.0756, g_loss: 6.7321, D(x): 0.97, D(G(z)): 0.02\n","Epoch [15/200], Step [400/600], d_loss: 0.1009, g_loss: 4.6616, D(x): 0.98, D(G(z)): 0.04\n","Epoch [15/200], Step [600/600], d_loss: 0.1622, g_loss: 4.3271, D(x): 0.97, D(G(z)): 0.08\n","Epoch [16/200], Step [200/600], d_loss: 0.1660, g_loss: 4.6276, D(x): 0.97, D(G(z)): 0.07\n","Epoch [16/200], Step [400/600], d_loss: 0.1222, g_loss: 4.6952, D(x): 0.96, D(G(z)): 0.05\n","Epoch [16/200], Step [600/600], d_loss: 0.2420, g_loss: 5.0053, D(x): 0.97, D(G(z)): 0.09\n","Epoch [17/200], Step [200/600], d_loss: 0.1898, g_loss: 2.8592, D(x): 0.91, D(G(z)): 0.03\n","Epoch [17/200], Step [400/600], d_loss: 0.2189, g_loss: 4.0449, D(x): 0.93, D(G(z)): 0.04\n","Epoch [17/200], Step [600/600], d_loss: 0.1544, g_loss: 5.5196, D(x): 0.95, D(G(z)): 0.02\n","Epoch [18/200], Step [200/600], d_loss: 0.0838, g_loss: 5.5605, D(x): 0.98, D(G(z)): 0.04\n","Epoch [18/200], Step [400/600], d_loss: 0.1417, g_loss: 5.7512, D(x): 0.96, D(G(z)): 0.05\n","Epoch [18/200], Step [600/600], d_loss: 0.3113, g_loss: 3.5488, D(x): 0.92, D(G(z)): 0.10\n","Epoch [19/200], Step [200/600], d_loss: 0.1392, g_loss: 5.4078, D(x): 0.96, D(G(z)): 0.04\n","Epoch [19/200], Step [400/600], d_loss: 0.2098, g_loss: 4.7614, D(x): 0.94, D(G(z)): 0.05\n","Epoch [19/200], Step [600/600], d_loss: 0.2229, g_loss: 4.3993, D(x): 0.93, D(G(z)): 0.05\n","Epoch [20/200], Step [200/600], d_loss: 0.3000, g_loss: 4.1296, D(x): 0.93, D(G(z)): 0.11\n","Epoch [20/200], Step [400/600], d_loss: 0.1013, g_loss: 5.5295, D(x): 0.96, D(G(z)): 0.02\n","Epoch [20/200], Step [600/600], d_loss: 0.2755, g_loss: 3.2922, D(x): 0.96, D(G(z)): 0.14\n","Epoch [21/200], Step [200/600], d_loss: 0.5015, g_loss: 4.2305, D(x): 0.84, D(G(z)): 0.06\n","Epoch [21/200], Step [400/600], d_loss: 0.2364, g_loss: 4.4964, D(x): 0.92, D(G(z)): 0.07\n","Epoch [21/200], Step [600/600], d_loss: 0.1820, g_loss: 4.7706, D(x): 0.95, D(G(z)): 0.09\n","Epoch [22/200], Step [200/600], d_loss: 0.2198, g_loss: 4.8897, D(x): 0.91, D(G(z)): 0.02\n","Epoch [22/200], Step [400/600], d_loss: 0.2379, g_loss: 4.4568, D(x): 0.93, D(G(z)): 0.07\n","Epoch [22/200], Step [600/600], d_loss: 0.2185, g_loss: 4.2077, D(x): 0.98, D(G(z)): 0.11\n","Epoch [23/200], Step [200/600], d_loss: 0.2514, g_loss: 5.2312, D(x): 0.92, D(G(z)): 0.04\n","Epoch [23/200], Step [400/600], d_loss: 0.1412, g_loss: 6.6959, D(x): 0.92, D(G(z)): 0.00\n","Epoch [23/200], Step [600/600], d_loss: 0.3079, g_loss: 3.5836, D(x): 0.95, D(G(z)): 0.12\n","Epoch [24/200], Step [200/600], d_loss: 0.2003, g_loss: 3.6033, D(x): 0.93, D(G(z)): 0.07\n","Epoch [24/200], Step [400/600], d_loss: 0.1796, g_loss: 5.3199, D(x): 0.91, D(G(z)): 0.03\n","Epoch [24/200], Step [600/600], d_loss: 0.2986, g_loss: 4.8572, D(x): 0.90, D(G(z)): 0.06\n","Epoch [25/200], Step [200/600], d_loss: 0.4762, g_loss: 3.3669, D(x): 0.85, D(G(z)): 0.09\n","Epoch [25/200], Step [400/600], d_loss: 0.3987, g_loss: 3.7425, D(x): 0.96, D(G(z)): 0.21\n","Epoch [25/200], Step [600/600], d_loss: 0.1759, g_loss: 4.7525, D(x): 0.99, D(G(z)): 0.12\n","Epoch [26/200], Step [200/600], d_loss: 0.2235, g_loss: 5.2407, D(x): 0.92, D(G(z)): 0.03\n","Epoch [26/200], Step [400/600], d_loss: 0.2668, g_loss: 4.0988, D(x): 0.93, D(G(z)): 0.09\n","Epoch [26/200], Step [600/600], d_loss: 0.1995, g_loss: 3.4545, D(x): 0.96, D(G(z)): 0.08\n","Epoch [27/200], Step [200/600], d_loss: 0.2943, g_loss: 5.0924, D(x): 0.97, D(G(z)): 0.17\n","Epoch [27/200], Step [400/600], d_loss: 0.3385, g_loss: 3.2524, D(x): 0.90, D(G(z)): 0.10\n","Epoch [27/200], Step [600/600], d_loss: 0.2852, g_loss: 4.6314, D(x): 0.89, D(G(z)): 0.05\n","Epoch [28/200], Step [200/600], d_loss: 0.3636, g_loss: 3.4667, D(x): 0.90, D(G(z)): 0.08\n","Epoch [28/200], Step [400/600], d_loss: 0.5777, g_loss: 4.3424, D(x): 0.92, D(G(z)): 0.24\n","Epoch [28/200], Step [600/600], d_loss: 0.3972, g_loss: 3.6151, D(x): 0.90, D(G(z)): 0.11\n","Epoch [29/200], Step [200/600], d_loss: 0.2825, g_loss: 4.8856, D(x): 0.90, D(G(z)): 0.03\n","Epoch [29/200], Step [400/600], d_loss: 0.2003, g_loss: 3.4466, D(x): 0.93, D(G(z)): 0.07\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NQWNXBVqfqcl","colab_type":"text"},"source":["# MNIST로 GAN 실습하기\n","### 01. MNIST 데이터 불러오기"]},{"cell_type":"code","metadata":{"id":"VMa7lwI6mi05","colab_type":"code","colab":{}},"source":["import os\n","import torch\n","import torchvision\n","import torch.nn as nn\n","from torchvision import transforms\n","from torchvision.utils import save_image\n","\n","\n","# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Hyper-parameters\n","latent_size = 64\n","hidden_size = 256\n","image_size = 784\n","num_epochs = 200\n","batch_size = 100\n","sample_dir = 'samples'\n","\n","# Create a directory if not exists\n","if not os.path.exists(sample_dir):\n","    os.makedirs(sample_dir)\n","\n","# Image processing\n","# transform = transforms.Compose([\n","#                 transforms.ToTensor(),\n","#                 transforms.Normalize(mean=(0.5, 0.5, 0.5),   # 3 for RGB channels\n","#                                      std=(0.5, 0.5, 0.5))])\n","transform = transforms.Compose([\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean=[0.5],   # 1 for greyscale channels\n","                                     std=[0.5])])\n","\n","# MNIST dataset\n","mnist = torchvision.datasets.MNIST(root='../../data/',\n","                                   train=True,\n","                                   transform=transform,\n","                                   download=True)\n","\n","# Data loader\n","data_loader = torch.utils.data.DataLoader(dataset=mnist,\n","                                          batch_size=batch_size, \n","                                          shuffle=True)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WnjyBy4Gg2zw","colab_type":"text"},"source":["### 02. Discriminator, Generator 정의\n","* G : 100차원의 가우시안 디스트리뷰션에서 샘플링한 노이즈 z를 이용하여 MNIST 데이터를 만들어내는 ML\n","* D : 주어진 이미지가 실제 데이터인지 아니면 G에 의해 만들어진 데이터인지 판별"]},{"cell_type":"code","metadata":{"id":"nnfNpJFag1sj","colab_type":"code","colab":{}},"source":["# Discriminator\n","# define the discriminator : input size = 784, hidden size = 128, output size = 1 (as binary value)\n","D = nn.Sequential(\n","    nn.Linear(image_size, hidden_size),\n","    nn.LeakyReLU(0.2),\n","    nn.Linear(hidden_size, hidden_size),\n","    nn.LeakyReLU(0.2),\n","    nn.Linear(hidden_size, 1),\n","    nn.Sigmoid()) # 0 to 1 normalizatino \n","\n","# Generator \n","# define the generator : input size = 100(latent vector of 100 dimension), hidden size = 128, output size = 784 (as make fake image)\n","G = nn.Sequential(\n","    nn.Linear(latent_size, hidden_size),\n","    nn.ReLU(),\n","    nn.Linear(hidden_size, hidden_size),\n","    nn.ReLU(),\n","    nn.Linear(hidden_size, image_size),\n","    nn.Tanh()) # -1 to 1 normalization. option\n","\n","# Device setting\n","D = D.to(device)\n","G = G.to(device)\n","\n","# Binary Cross Entropy Loss and optimizer \n","# (h(x),y) = -ylogh(x) - (1-y)log(1-h(x)). h(x) :prediction value a.k.a. D(x), y : label\n","criterion = nn.BCELoss() #use binary cross entropy loss function with fake label (1) -> maxEz~pz(z)[logD(G(z))]\n","\n","# Optimizer using Adam for D and G : 충돌되는 함수이기 때문에 각각 구현해야됨\n","d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0002)\n","g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002)\n","\n","# x is a tensor of shape (batch_size, 784) -> real\n","# z is a tensor of shape (batch_size, 100) -> random vector for fake image\n","\n","def denorm(x):\n","    out = (x + 1) / 2 # \n","    return out.clamp(0, 1) # Clamp all elements in input into the range [ min, max ] and return a resulting tensor:\n","\n","def reset_grad():\n","    d_optimizer.zero_grad()\n","    g_optimizer.zero_grad()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6Uh7H1wvg701","colab_type":"text"},"source":["### 03. 모델 학습"]},{"cell_type":"code","metadata":{"id":"GX-GejQemmqE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":247},"executionInfo":{"status":"error","timestamp":1593881803457,"user_tz":-540,"elapsed":1143,"user":{"displayName":"이지혜","photoUrl":"","userId":"00746562838578381732"}},"outputId":"e34d14d6-5117-4cc5-ce69-2261aa09f4ff"},"source":["# Start training\n","total_step = len(data_loader)\n","for epoch in range(num_epochs):\n","    for i, (images, _) in enumerate(data_loader):\n","        images = images.reshape(batch_size, -1).to(device)\n","        \n","        # Create the labels which are later used as input for the BCE loss\n","        real_labels = torch.ones(batch_size, 1).to(device)\n","        fake_labels = torch.zeros(batch_size, 1).to(device)\n","\n","        # ================================================================== #\n","        #                      Train the discriminator                       #\n","        # ================================================================== #\n","\n","        # Compute BCE_Loss using real images where BCE_Loss(x, y): - y * log(D(x)) - (1-y) * log(1 - D(x))\n","        ## Second term of the loss is always zero since real_labels == 1\n","        outputs = D(images)\n","        d_loss_real = criterion(outputs, real_labels)\n","        real_score = outputs\n","        \n","        # Compute BCELoss using fake images\n","        ## First term of the loss is always zero since fake_labels == 0\n","        z = torch.randn(batch_size, latent_size).to(device)\n","        fake_images = G(z)\n","        outputs = D(fake_images)\n","        d_loss_fake = criterion(outputs, fake_labels)\n","        fake_score = outputs\n","        \n","        # Backprop and optimize\n","        # forward, backward, and gradient descent. loss를 최소화하도록 학습함 -> 가짜는 0, 진짜는 1에 가깝게 학습\n","        d_loss = d_loss_real + d_loss_fake\n","        reset_grad()\n","        d_loss.backward()\n","        d_optimizer.step()\n"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-63120f5e7d64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtotal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'data_loader' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"a3hEcJqWfSx8","colab_type":"text"},"source":["### generator 학습\n","* generator가 학습할 때, discriminator는 고정을 해야됨     \n","* D(G(z))값과  1과 차이값을 계산하여 backpropagation을 하되, discriminator의  weight와 bias는 학습하지 않음 (generator에서만 함)"]},{"cell_type":"code","metadata":{"id":"YoORmyQ4wh0j","colab_type":"code","colab":{}},"source":["\n","        # ================================================================== #\n","        #                        Train the generator                         #\n","        # ================================================================== #\n","\n","        # Compute loss with fake images\n","        z = torch.randn(batch_size, latent_size).to(device)\n","        fake_images = G(z)\n","        outputs = D(fake_images)\n","        \n","        # We train G to maximize log(D(G(z)) instead of minimizing log(1-D(G(z)))\n","        # For the reason, see the last paragraph of section 3. https://arxiv.org/pdf/1406.2661.pdf\n","        g_loss = criterion(outputs, real_labels)\n","        \n","        # Backprop and optimize\n","        reset_grad()\n","        g_loss.backward()\n","        g_optimizer.step()\n","        \n","        if (i+1) % 200 == 0:\n","            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n","                  .format(epoch, num_epochs, i+1, total_step, d_loss.item(), g_loss.item(), \n","                          real_score.mean().item(), fake_score.mean().item()))\n","    \n","    # Save real images\n","    if (epoch+1) == 1:\n","        images = images.reshape(images.size(0), 1, 28, 28)\n","        save_image(denorm(images), os.path.join(sample_dir, 'real_images.png'))\n","    \n","    # Save sampled images\n","    fake_images = fake_images.reshape(fake_images.size(0), 1, 28, 28)\n","    save_image(denorm(fake_images), os.path.join(sample_dir, 'fake_images-{}.png'.format(epoch+1)))\n","\n","# Save the model checkpoints \n","torch.save(G.state_dict(), 'G.ckpt')\n","torch.save(D.state_dict(), 'D.ckpt'"],"execution_count":null,"outputs":[]}]}